defaultNamespace: datadog-system

helm:
  repo: https://helm.datadoghq.com
  chart: datadog
  version: "3.33.3"
  releaseName: datadog
# Datadog cannot autodetect the cluster name on vSphere, and Rancher clusters are always called `local`,
# "management.cattle.io/cluster-display-name-local" is not unique
# ref. https://docs.datadoghq.com/agent/guide/kubernetes-cluster-name-detection
targetCustomizations:
  # AWS Ranchers
  - name: awsranchers
    clusterSelector:
      matchLabels:
        cloud: aws
        rancher_dedicated: true
    helm:
      values:
        datadog:
          prometheusScrape:
            enabled: false
            serviceEndpoints: false
          env:
            - name: DD_CLUSTER_NAME
              value: global.fleet.clusterLabels.cluster-name
          tags:
            - xcr_environment:${ get .ClusterLabels "xcr-alerts" }
        clusterAgent:
          confd:
            kube_apiserver_metrics.yaml: |-
              cluster_check: true
              init_config:
              instances:
                - prometheus_url: https://%%env_KUBERNETES_SERVICE_HOST%%:443/metrics
                  bearer_token_auth: true
                  tags:
                    - xcr_environment:${ get .ClusterLabels "xcr-alerts" }
          env:
            - name: DD_CLUSTER_NAME
              value: global.fleet.clusterLabels.cluster-name
      valuesFiles:
        - values-aws.yaml
  # vSphere Ranchers
  - name: vsphereranchers
    clusterSelector:
      matchLabels:
        cloud: vsphere
        rancher_dedicated: true
    helm:
      values:
        datadog:
          prometheusScrape:
            enabled: false
            serviceEndpoints: false
          env:
            - name: DD_CLUSTER_NAME
              value: global.fleet.clusterLabels.cluster-name
          tags:
            - xcr_environment:${ get .ClusterLabels "xcr-alerts" }
        clusterAgent:
          confd:
            kube_apiserver_metrics.yaml: |-
              cluster_check: true
              init_config:
              instances:
                - prometheus_url: https://%%env_KUBERNETES_SERVICE_HOST%%:443/metrics
                  bearer_token_auth: true
                  tags:
                    - xcr_environment:${ get .ClusterLabels "xcr-alerts" }
          env:
            - name: DD_CLUSTER_NAME
              value: global.fleet.clusterLabels.cluster-name
      valuesFiles:
        - values-vsphere.yaml
  # TCX AWS clusters
  - name: aws-usea1-tcx-preprod
    clusterSelector:
      matchLabels:
        cloud: aws
        owner: tcx
    helm:
      values:
        datadog:
          prometheusScrape:
            enabled: true
            serviceEndpoints: true
          env:
            - name: DD_CLUSTER_NAME
              value: global.fleet.clusterLabels.management.cattle.io/cluster-display-name
          tags:
            - xcr_environment:${ get .ClusterLabels "xcr-alerts" }
        clusterAgent:
          confd:
            kube_apiserver_metrics.yaml: |-
              cluster_check: true
              init_config:
              instances:
                - prometheus_url: https://%%env_KUBERNETES_SERVICE_HOST%%:443/metrics
                  bearer_token_auth: true
                  tags:
                    - xcr_environment:${ get .ClusterLabels "xcr-alerts" }
          env:
            - name: DD_CLUSTER_NAME
              value: global.fleet.clusterLabels.management.cattle.io/cluster-display-name
      valuesFiles:
        - values-aws.yaml
  # AWS Ranchers
  - name: awsdefault
    clusterSelector:
      matchLabels:
        cloud: aws
    helm:
      values:
        datadog:
          prometheusScrape:
            enabled: false
            serviceEndpoints: false
          env:
            - name: DD_CLUSTER_NAME
              value: global.fleet.clusterLabels.management.cattle.io/cluster-display-name
          tags:
            - xcr_environment:${ get .ClusterLabels "xcr-alerts" }
        clusterAgent:
          confd:
            kube_apiserver_metrics.yaml: |-
              cluster_check: true
              init_config:
              instances:
                - prometheus_url: https://%%env_KUBERNETES_SERVICE_HOST%%:443/metrics
                  bearer_token_auth: true
                  tags:
                    - xcr_environment:${ get .ClusterLabels "xcr-alerts" }
          env:
            - name: DD_CLUSTER_NAME
              value: global.fleet.clusterLabels.management.cattle.io/cluster-display-name
      valuesFiles:
        - values-aws.yaml
  # vSphere Ranchers
  - name: vspheredefault
    clusterSelector:
      matchLabels:
        cloud: vsphere
    helm:
      values:
        datadog:
          prometheusScrape:
            enabled: false
            serviceEndpoints: false
          env:
            - name: DD_CLUSTER_NAME
              value: global.fleet.clusterLabels.management.cattle.io/cluster-display-name
          tags:
            - xcr_environment:${ get .ClusterLabels "xcr-alerts" }
        clusterAgent:
          confd:
            kube_apiserver_metrics.yaml: |-
              cluster_check: true
              init_config:
              instances:
                - prometheus_url: https://%%env_KUBERNETES_SERVICE_HOST%%:443/metrics
                  bearer_token_auth: true
                  tags:
                    - xcr_environment:${ get .ClusterLabels "xcr-alerts" }
          env:
            - name: DD_CLUSTER_NAME
              value: global.fleet.clusterLabels.management.cattle.io/cluster-display-name
      valuesFiles:
        - values-vsphere.yaml
